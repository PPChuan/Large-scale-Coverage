# run_parameters
run_p:
  pretrain_lr: &pretrain_lr 0.5
  ft_lr: &ft_lr 10.0
  pretrain_batch_size: 512
  ft_batch_size: 512
  val_batch_size: 512
  pretrain_epoch: &pretrain_epoch 500
  ft_epoch: &ft_epoch 100
  network: SimCLR
  dataset: &dataset Tiny200
  optimizer: &op SGD

#model
model:
  type: ResNet
  features_dim: 128
  maxpool: False
  depth: 34

# run_device
run_d :
  num_workers: 4

# criterion, loss
loss:
  pretrain:
    type: NT_Xent_dist
    temperature: 0.5
    base_temperature: 0.07
  ft:
    type: CrossEntropyLoss

# optimizer
op:
  pretrain:
    type: *op
    lr: *pretrain_lr
    momentum: 0.9
    weight_decay: 0.0001
  ft:
    type: *op
    lr: *ft_lr
    momentum: 0.9
    weight_decay: 0

# dataset
dataset:
  root: ./data
  type: *dataset
  num_classes: 200
  pretrain:
    type: Tiny200_rcrop
    transform:
      type: tiny200_train_rcrop
      mean: 0.4802, 0.4481, 0.3975
      std: 0.2302, 0.2265, 0.2262
  ft:
    transform:
      type: tiny200_linear
      mean: 0.4802, 0.4481, 0.3975
      std: 0.2302, 0.2265, 0.2262
  val:
    transform:
      type: tiny200_test
      mean: 0.4802, 0.4481, 0.3975
      std: 0.2302, 0.2265, 0.2262

# adjust lr
lr_cfg:
  pretrain :
    type: Cosine
    steps: *pretrain_epoch
    lr: *pretrain_lr
    decay_rate: 0.07
    re_lr: 0
    warmup_steps: 0
  ft :
    type: MultiStep
    steps: *ft_epoch
    lr: *ft_lr
    decay_rate: 0.1
    decay_steps:
      - 60
      - 80

port: 10001
save_interval:
  pretrain: 250
  ft: 50